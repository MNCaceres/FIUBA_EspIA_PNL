{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZd5yLnnHOK0"
      },
      "source": [
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Custom embedddings con Gensim\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA7nqkumo9z9"
      },
      "source": [
        "### Objetivo\n",
        "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto. Se utilizará canciones de bandas para generar los embeddings, es decir, que los vectores tendrán la forma en función de como esa banda haya utilizado las palabras en sus canciones."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consigna"
      ],
      "metadata": {
        "id": "PB9qZEIAzrB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
        "- Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
        "- Intentar plantear y probar tests de analogías.\n",
        "- Graficarlos.\n",
        "- Obtener conclusiones."
      ],
      "metadata": {
        "id": "S_Pd0V_Lzwf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resolución"
      ],
      "metadata": {
        "id": "ix-xLGcV0Fdm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07zJxG7H9vG"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset \"Alice's Adventures in Wonderland\" (Alicia en el País de las Maravillas) de Lewis Carroll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFToQs5FK5uZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a7d0e5-1e30-4717-a122-e77f135e6da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Librerias\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import requests\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from gensim.models.callbacks import CallbackAny2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leemos el archivo desde la URL usando requests\n",
        "url = 'https://www.gutenberg.org/files/11/11-0.txt'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Obtenemos el contenido del archivo como texto\n",
        "raw_text = response.text\n",
        "\n",
        "# Dividimos el texto en oraciones usando nltk\n",
        "sentences = nltk.sent_tokenize(raw_text)\n",
        "\n",
        "# Convertimos las oraciones en un DataFrame\n",
        "df = pd.DataFrame(sentences, columns=[\"text\"])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kloQulY35I3U",
        "outputId": "01c2c86c-5697-4b54-9169-ded05de9c372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  ï»¿ï»¿*** START OF THE PROJECT GUTENBERG EBOOK...\n",
              "1               Down the Rabbit-Hole\\r\\n CHAPTER II.\n",
              "2                 The Pool of Tears\\r\\n CHAPTER III.\n",
              "3      A Caucus-Race and a Long Tale\\r\\n CHAPTER IV.\n",
              "4  The Rabbit Sends in a Little Bill\\r\\n CHAPTER ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d44723a8-baa7-4ab5-bc1c-095347d9128b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ï»¿ï»¿*** START OF THE PROJECT GUTENBERG EBOOK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Down the Rabbit-Hole\\r\\n CHAPTER II.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Pool of Tears\\r\\n CHAPTER III.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A Caucus-Race and a Long Tale\\r\\n CHAPTER IV.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Rabbit Sends in a Little Bill\\r\\n CHAPTER ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d44723a8-baa7-4ab5-bc1c-095347d9128b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d44723a8-baa7-4ab5-bc1c-095347d9128b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d44723a8-baa7-4ab5-bc1c-095347d9128b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80ed42df-9179-4032-bc0d-4f6c506f7ceb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80ed42df-9179-4032-bc0d-4f6c506f7ceb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80ed42df-9179-4032-bc0d-4f6c506f7ceb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 985,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 977,\n        \"samples\": [\n          \"\\u00e2\\u0080\\u009cYou insult me by talking such nonsense!\\u00e2\\u0080\\u009d\\r\\n\\r\\n\\u00e2\\u0080\\u009cI didn\\u00e2\\u0080\\u0099t mean it!\\u00e2\\u0080\\u009d pleaded poor Alice.\",\n          \"\\u00e2\\u0080\\u009cI wasn\\u00e2\\u0080\\u0099t asleep,\\u00e2\\u0080\\u009d he said in a\\r\\nhoarse, feeble voice: \\u00e2\\u0080\\u009cI heard every word you fellows were saying.\\u00e2\\u0080\\u009d\\r\\n\\r\\n\\u00e2\\u0080\\u009cTell us a story!\\u00e2\\u0080\\u009d said the March Hare.\",\n          \"\\u00e2\\u0080\\u009cI don\\u00e2\\u0080\\u0099t know the meaning of half\\r\\nthose long words, and, what\\u00e2\\u0080\\u0099s more, I don\\u00e2\\u0080\\u0099t believe you do either!\\u00e2\\u0080\\u009d And\\r\\nthe Eaglet bent down its head to hide a smile: some of the other birds\\r\\ntittered audibly.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEpKubK9XzXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e21bff9-0e52-404d-f072-7011f12fe903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de documentos: 985\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab94qaFlrA1G"
      },
      "source": [
        "### 1 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para limpiar el texto\n",
        "def clean_text(text):\n",
        "\n",
        "    # Reemplazamos saltos de línea y retornos de carro por espacios\n",
        "    text = text.replace('\\r', ' ').replace('\\n', ' ')\n",
        "\n",
        "    # Eliminamos caracteres no deseados (usar expresiones regulares)\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Elimina caracteres no ASCII\n",
        "\n",
        "    return text\n",
        "\n",
        "# Función para eliminar los metadatos de Proyecto Gutenberg\n",
        "def remove_gutenberg_metadata(text):\n",
        "\n",
        "    # Identificamos y eliminamos los metadatos iniciales (después del título del libro)\n",
        "    start_idx = text.lower().find(\"chapter i\")  # Buscar el primer capítulo de forma flexible\n",
        "\n",
        "    # Buscamos el final del txto\n",
        "    end_idx = text.lower().rfind(\"end of the project gutenberg\")\n",
        "\n",
        "    # Si no se encuentra el texto, devolverlo como está\n",
        "    if start_idx == -1:\n",
        "        start_idx = 0\n",
        "    if end_idx == -1:\n",
        "        end_idx = len(text)\n",
        "\n",
        "    # Cortar el texto desde el inicio real hasta el final real\n",
        "    return text[start_idx:end_idx]\n",
        "\n",
        "# Leemos el archivo como texto completo\n",
        "url = 'https://www.gutenberg.org/files/11/11-0.txt'\n",
        "response = requests.get(url)\n",
        "raw_text = response.text\n",
        "\n",
        "# Limpiamos el texto y eliminamos los metadatos\n",
        "cleaned_text = clean_text(raw_text)\n",
        "cleaned_text = remove_gutenberg_metadata(cleaned_text)\n",
        "\n",
        "# Dividimos en oraciones\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sentence_tokens = sent_tokenize(cleaned_text)\n",
        "\n",
        "# Filtramos oraciones que son solo títulos de capítulos o vacías\n",
        "sentence_tokens = [sent for sent in sentence_tokens if not re.search(r'chapter \\w+', sent.lower()) and len(sent.strip()) > 5]\n",
        "\n",
        "# Convertimos las oraciones a listas de palabras usando text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "word_tokens = []\n",
        "for sentence in sentence_tokens:\n",
        "    word_tokens.append(text_to_word_sequence(sentence))\n",
        "\n",
        "# Damos un vistazo a las primeras secuencias de palabras\n",
        "word_tokens[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4baH2_VFHf0",
        "outputId": "9c019e8f-16d0-45fc-fcc1-a3452226b4ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['who', 'stole', 'the', 'tarts'],\n",
              " ['down',\n",
              "  'the',\n",
              "  'rabbit',\n",
              "  'hole',\n",
              "  'alice',\n",
              "  'was',\n",
              "  'beginning',\n",
              "  'to',\n",
              "  'get',\n",
              "  'very',\n",
              "  'tired',\n",
              "  'of',\n",
              "  'sitting',\n",
              "  'by',\n",
              "  'her',\n",
              "  'sister',\n",
              "  'on',\n",
              "  'the',\n",
              "  'bank',\n",
              "  'and',\n",
              "  'of',\n",
              "  'having',\n",
              "  'nothing',\n",
              "  'to',\n",
              "  'do',\n",
              "  'once',\n",
              "  'or',\n",
              "  'twice',\n",
              "  'she',\n",
              "  'had',\n",
              "  'peeped',\n",
              "  'into',\n",
              "  'the',\n",
              "  'book',\n",
              "  'her',\n",
              "  'sister',\n",
              "  'was',\n",
              "  'reading',\n",
              "  'but',\n",
              "  'it',\n",
              "  'had',\n",
              "  'no',\n",
              "  'pictures',\n",
              "  'or',\n",
              "  'conversations',\n",
              "  'in',\n",
              "  'it',\n",
              "  'and',\n",
              "  'what',\n",
              "  'is',\n",
              "  'the',\n",
              "  'use',\n",
              "  'of',\n",
              "  'a',\n",
              "  'book',\n",
              "  'thought',\n",
              "  'alice',\n",
              "  'without',\n",
              "  'pictures',\n",
              "  'or',\n",
              "  'conversations'],\n",
              " ['so',\n",
              "  'she',\n",
              "  'was',\n",
              "  'considering',\n",
              "  'in',\n",
              "  'her',\n",
              "  'own',\n",
              "  'mind',\n",
              "  'as',\n",
              "  'well',\n",
              "  'as',\n",
              "  'she',\n",
              "  'could',\n",
              "  'for',\n",
              "  'the',\n",
              "  'hot',\n",
              "  'day',\n",
              "  'made',\n",
              "  'her',\n",
              "  'feel',\n",
              "  'very',\n",
              "  'sleepy',\n",
              "  'and',\n",
              "  'stupid',\n",
              "  'whether',\n",
              "  'the',\n",
              "  'pleasure',\n",
              "  'of',\n",
              "  'making',\n",
              "  'a',\n",
              "  'daisy',\n",
              "  'chain',\n",
              "  'would',\n",
              "  'be',\n",
              "  'worth',\n",
              "  'the',\n",
              "  'trouble',\n",
              "  'of',\n",
              "  'getting',\n",
              "  'up',\n",
              "  'and',\n",
              "  'picking',\n",
              "  'the',\n",
              "  'daisies',\n",
              "  'when',\n",
              "  'suddenly',\n",
              "  'a',\n",
              "  'white',\n",
              "  'rabbit',\n",
              "  'with',\n",
              "  'pink',\n",
              "  'eyes',\n",
              "  'ran',\n",
              "  'close',\n",
              "  'by',\n",
              "  'her'],\n",
              " ['there',\n",
              "  'was',\n",
              "  'nothing',\n",
              "  'so',\n",
              "  'very',\n",
              "  'remarkable',\n",
              "  'in',\n",
              "  'that',\n",
              "  'nor',\n",
              "  'did',\n",
              "  'alice',\n",
              "  'think',\n",
              "  'it',\n",
              "  'so',\n",
              "  'very',\n",
              "  'much',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'way',\n",
              "  'to',\n",
              "  'hear',\n",
              "  'the',\n",
              "  'rabbit',\n",
              "  'say',\n",
              "  'to',\n",
              "  'itself',\n",
              "  'oh',\n",
              "  'dear'],\n",
              " ['oh', 'dear']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Filtramos las oraciones para eliminar stop words\n",
        "sentence_tokens_filtered = [\n",
        "    [word for word in text_to_word_sequence(sentence) if word not in stop_words]\n",
        "    for sentence in sentence_tokens\n",
        "]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wiL1TT8NaX9",
        "outputId": "281e4b85-b985-47aa-c94b-ae460f6edf29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificamos las oraciones antes del filtrado\n",
        "print(\"Oraciones originales (antes de filtrar palabras vacías):\")\n",
        "print(sentence_tokens[:5])  # Muestramos las primeras 5 oraciones originales\n",
        "\n",
        "# Imprimimos las oraciones filtradas\n",
        "print(\"\\nOraciones filtradas (después de eliminar palabras vacías):\")\n",
        "print(sentence_tokens_filtered[:5])  # Muestra las primeras 5 oraciones filtradas\n",
        "\n",
        "# Contamos la frecuencia de palabras en sentence_tokens y sentence_tokens_filtered\n",
        "# Unimos todas las palabras en una sola lista\n",
        "all_words_original = [word for sentence in sentence_tokens for word in text_to_word_sequence(sentence)]\n",
        "all_words_filtered = [word for sentence in sentence_tokens_filtered for word in sentence]  # Ya son listas de palabras\n",
        "\n",
        "# Contamos las frecuencias\n",
        "frequency_original = Counter(all_words_original)\n",
        "frequency_filtered = Counter(all_words_filtered)\n",
        "\n",
        "# Imprimimos las 10 palabras más comunes en cada caso\n",
        "print(\"\\n10 palabras más comunes en oraciones originales:\")\n",
        "print(frequency_original.most_common(10))\n",
        "\n",
        "print(\"\\n10 palabras más comunes en oraciones filtradas:\")\n",
        "print(frequency_filtered.most_common(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1umsKKGTdod",
        "outputId": "04362d3d-3bf6-454c-a7c2-cca60b442750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oraciones originales (antes de filtrar palabras vacías):\n",
            "['Who Stole the Tarts?', 'Down the Rabbit-Hole      Alice was beginning to get very tired of sitting by her sister on the  bank, and of having nothing to do: once or twice she had peeped into  the book her sister was reading, but it had no pictures or  conversations in it, and what is the use of a book, thought Alice  without pictures or conversations?', 'So she was considering in her own mind (as well as she could, for the  hot day made her feel very sleepy and stupid), whether the pleasure of  making a daisy-chain would be worth the trouble of getting up and  picking the daisies, when suddenly a White Rabbit with pink eyes ran  close by her.', 'There was nothing so _very_ remarkable in that; nor did Alice think it  so _very_ much out of the way to hear the Rabbit say to itself, Oh  dear!', 'Oh dear!']\n",
            "\n",
            "Oraciones filtradas (después de eliminar palabras vacías):\n",
            "[['stole', 'tarts'], ['rabbit', 'hole', 'alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', 'use', 'book', 'thought', 'alice', 'without', 'pictures', 'conversations'], ['considering', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', 'whether', 'pleasure', 'making', 'daisy', 'chain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', 'suddenly', 'white', 'rabbit', 'pink', 'eyes', 'ran', 'close'], ['nothing', 'remarkable', 'alice', 'think', 'much', 'way', 'hear', 'rabbit', 'say', 'oh', 'dear'], ['oh', 'dear']]\n",
            "\n",
            "10 palabras más comunes en oraciones originales:\n",
            "[('the', 1633), ('and', 850), ('to', 725), ('a', 626), ('she', 539), ('it', 528), ('of', 510), ('said', 462), ('i', 401), ('alice', 385)]\n",
            "\n",
            "10 palabras más comunes en oraciones filtradas:\n",
            "[('said', 462), ('alice', 385), ('little', 128), ('one', 101), ('like', 85), ('know', 85), ('would', 83), ('went', 83), ('could', 77), ('thought', 74)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaXV6nlHr5Aa"
      },
      "source": [
        "### 2 - Crear los vectores (word2vec)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSb0v7h8r7hK"
      },
      "outputs": [],
      "source": [
        "# Durante el entrenamiento la librería gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobrecargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0wnDdv9sJ47"
      },
      "outputs": [],
      "source": [
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=10,       # cant de palabras antes y desp de la predicha\n",
        "                     vector_size=50,       # dimensionalidad de los vectores\n",
        "                     negative=20,    # cantidad de negative samples... 0 no se usa\n",
        "                     workers=2,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1,\n",
        "                     alpha=0.03,    # Tasa de aprendizaje inicial\n",
        "                    min_alpha=0.0001) # modelo 0:CBOW  1:skipgram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lTt8wErsf17"
      },
      "outputs": [],
      "source": [
        "# Obtenemos el vocabulario con los tokens\n",
        "w2v_model.build_vocab(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNc9qt4os5AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f9bf29-3744-49d4-cd70-2e74d7fd7648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 1576\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idw9cHF3tSMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049c6faa-eafd-421e-890f-eba2bbabde4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de words distintas en el corpus: 687\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.index_to_key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC9mZ8DPk-UC"
      },
      "source": [
        "### 3 - Entrenar embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSp-x0PAsq56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3682fcd9-6ee8-43f4-f74b-5d2a442e8aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 150207.625\n",
            "Loss after epoch 1: 122413.21875\n",
            "Loss after epoch 2: 122262.1875\n",
            "Loss after epoch 3: 122199.25\n",
            "Loss after epoch 4: 122396.65625\n",
            "Loss after epoch 5: 119458.5625\n",
            "Loss after epoch 6: 119358.5\n",
            "Loss after epoch 7: 118164.125\n",
            "Loss after epoch 8: 113152.125\n",
            "Loss after epoch 9: 109595.625\n",
            "Loss after epoch 10: 108353.0\n",
            "Loss after epoch 11: 107432.5\n",
            "Loss after epoch 12: 104396.75\n",
            "Loss after epoch 13: 102075.0\n",
            "Loss after epoch 14: 102754.125\n",
            "Loss after epoch 15: 101187.375\n",
            "Loss after epoch 16: 101192.375\n",
            "Loss after epoch 17: 99269.75\n",
            "Loss after epoch 18: 96469.25\n",
            "Loss after epoch 19: 92038.75\n",
            "Loss after epoch 20: 92362.25\n",
            "Loss after epoch 21: 92086.25\n",
            "Loss after epoch 22: 92729.0\n",
            "Loss after epoch 23: 92088.25\n",
            "Loss after epoch 24: 90585.25\n",
            "Loss after epoch 25: 91631.5\n",
            "Loss after epoch 26: 90452.75\n",
            "Loss after epoch 27: 89844.75\n",
            "Loss after epoch 28: 91771.75\n",
            "Loss after epoch 29: 92129.0\n",
            "Loss after epoch 30: 91603.25\n",
            "Loss after epoch 31: 91680.75\n",
            "Loss after epoch 32: 91329.25\n",
            "Loss after epoch 33: 91140.25\n",
            "Loss after epoch 34: 90350.0\n",
            "Loss after epoch 35: 91628.5\n",
            "Loss after epoch 36: 90925.25\n",
            "Loss after epoch 37: 91810.0\n",
            "Loss after epoch 38: 90444.75\n",
            "Loss after epoch 39: 89846.5\n",
            "Loss after epoch 40: 90840.25\n",
            "Loss after epoch 41: 86128.25\n",
            "Loss after epoch 42: 82808.0\n",
            "Loss after epoch 43: 81884.5\n",
            "Loss after epoch 44: 81931.5\n",
            "Loss after epoch 45: 81984.0\n",
            "Loss after epoch 46: 82764.0\n",
            "Loss after epoch 47: 82809.5\n",
            "Loss after epoch 48: 81634.5\n",
            "Loss after epoch 49: 83383.0\n",
            "Loss after epoch 50: 81151.5\n",
            "Loss after epoch 51: 80934.5\n",
            "Loss after epoch 52: 81433.5\n",
            "Loss after epoch 53: 81485.5\n",
            "Loss after epoch 54: 82159.0\n",
            "Loss after epoch 55: 82292.0\n",
            "Loss after epoch 56: 83379.5\n",
            "Loss after epoch 57: 82608.5\n",
            "Loss after epoch 58: 82325.5\n",
            "Loss after epoch 59: 82279.0\n",
            "Loss after epoch 60: 82243.0\n",
            "Loss after epoch 61: 81621.5\n",
            "Loss after epoch 62: 81392.0\n",
            "Loss after epoch 63: 82738.5\n",
            "Loss after epoch 64: 81056.5\n",
            "Loss after epoch 65: 81748.0\n",
            "Loss after epoch 66: 81261.5\n",
            "Loss after epoch 67: 81010.5\n",
            "Loss after epoch 68: 81074.0\n",
            "Loss after epoch 69: 81468.0\n",
            "Loss after epoch 70: 80749.5\n",
            "Loss after epoch 71: 81132.0\n",
            "Loss after epoch 72: 81150.0\n",
            "Loss after epoch 73: 80875.0\n",
            "Loss after epoch 74: 81132.5\n",
            "Loss after epoch 75: 81177.0\n",
            "Loss after epoch 76: 80502.5\n",
            "Loss after epoch 77: 80637.5\n",
            "Loss after epoch 78: 80774.0\n",
            "Loss after epoch 79: 81057.0\n",
            "Loss after epoch 80: 80205.5\n",
            "Loss after epoch 81: 80992.5\n",
            "Loss after epoch 82: 80214.5\n",
            "Loss after epoch 83: 80613.0\n",
            "Loss after epoch 84: 80722.5\n",
            "Loss after epoch 85: 80483.0\n",
            "Loss after epoch 86: 80506.5\n",
            "Loss after epoch 87: 80599.0\n",
            "Loss after epoch 88: 80300.0\n",
            "Loss after epoch 89: 80012.5\n",
            "Loss after epoch 90: 80786.0\n",
            "Loss after epoch 91: 80114.5\n",
            "Loss after epoch 92: 80257.5\n",
            "Loss after epoch 93: 71629.5\n",
            "Loss after epoch 94: 71712.0\n",
            "Loss after epoch 95: 71275.0\n",
            "Loss after epoch 96: 71223.0\n",
            "Loss after epoch 97: 72084.0\n",
            "Loss after epoch 98: 70872.0\n",
            "Loss after epoch 99: 71021.0\n",
            "Loss after epoch 100: 70870.0\n",
            "Loss after epoch 101: 71066.0\n",
            "Loss after epoch 102: 70077.0\n",
            "Loss after epoch 103: 70924.0\n",
            "Loss after epoch 104: 70991.0\n",
            "Loss after epoch 105: 71472.0\n",
            "Loss after epoch 106: 70998.0\n",
            "Loss after epoch 107: 70305.0\n",
            "Loss after epoch 108: 71224.0\n",
            "Loss after epoch 109: 70527.0\n",
            "Loss after epoch 110: 70193.0\n",
            "Loss after epoch 111: 70835.0\n",
            "Loss after epoch 112: 70979.0\n",
            "Loss after epoch 113: 70126.0\n",
            "Loss after epoch 114: 70124.0\n",
            "Loss after epoch 115: 70075.0\n",
            "Loss after epoch 116: 70168.0\n",
            "Loss after epoch 117: 69457.0\n",
            "Loss after epoch 118: 68762.0\n",
            "Loss after epoch 119: 69007.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1034325, 1521480)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model.train(sentence_tokens_filtered,\n",
        "                 total_examples=w2v_model.corpus_count,\n",
        "                 epochs=120,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anteriormente se hicieron diferentes pruebas en este mismo modelo, se hicieronc ambios en:\n",
        "\n",
        "\n",
        "*   Se eliminaron los stop word y se volvió a entrenar el modelo con el contenido filtrado.\n",
        "*   Se cambió el alpha=0.01 a 0.02 y luego a 0.03, llegando a mejores resultados.\n",
        "*   Se cambió windos=5 a windows=10\n",
        "*   Se aumento el número de épocas.\n",
        "\n",
        "\n",
        "Conclusiones:\n",
        "Se entiende que el modelo está teniendo una performance aceptable en cuanto la pérdida disminuye considerablemente en las primeras épocas, hay cierta inestabilidad en las 101 hasta la 112, pero luego se estabiliza y continua disminuyendo lo que puede sugerir que el modelo está encontrando un buen ajuste.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jre5aKIRW9Au"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddT9NVuNlCAe"
      },
      "source": [
        "### 4 - Ensayar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cHN9xGLuPEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0afb9b59-228e-4317-f479-83059a42028e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('white', 0.8125852942466736),\n",
              " ('curiosity', 0.5300334692001343),\n",
              " ('came', 0.5210338830947876),\n",
              " ('making', 0.5150903463363647),\n",
              " ('kid', 0.5113235116004944),\n",
              " ('alice', 0.507750391960144),\n",
              " ('gloves', 0.4912770390510559),\n",
              " ('chorus', 0.48106491565704346),\n",
              " ('everything', 0.4791344404220581),\n",
              " ('loud', 0.46909743547439575)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"rabbit\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este conjunto de resultados refleja que el modelo ha capturado correctamente las asociaciones semánticas clave del contexto de \"Alice's Adventures in Wonderland\". Tiene sentido que la palabra mas relacionada con \"rabbit\" sea \"white\" ya que uno de los personajes se llama de esa forma. A su vez, aparece la palabra \"curiosity\", y se puede interpretar que a \"Alice\" el conejo en la historia le genera curiosidad, lo cual es parte importante de la misma."
      ],
      "metadata": {
        "id": "PcCEANCmauDX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47HiU5gdkdMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc386569-45e7-4ae9-94b1-a41573d7048e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('did', 0.3096770644187927),\n",
              " ('once', 0.26930609345436096),\n",
              " ('be', 0.2676049470901489),\n",
              " ('being', 0.2670842409133911),\n",
              " ('your', 0.2441428154706955),\n",
              " ('each', 0.2189115732908249),\n",
              " ('should', 0.21669715642929077),\n",
              " ('or', 0.1972203254699707),\n",
              " ('him', 0.1784999668598175),\n",
              " ('no', 0.16871602833271027)]"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ],
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"queen\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este resultado parece indicar que el modelo ha captado que la palabra queen tiene un significado específico en el contexto del libro, y las palabras aquí mostradas son términos más generales, con menor relación directa."
      ],
      "metadata": {
        "id": "G8kh0S4Sc7ZW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT4Rvno2mD65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad7eacc-ae0c-4aff-8b9b-a91545321ccc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('times', 0.5937567353248596),\n",
              " ('seven', 0.5370975732803345),\n",
              " ('see', 0.5061035752296448),\n",
              " ('soup', 0.4929256737232208),\n",
              " ('cook', 0.48455601930618286),\n",
              " ('anxiously', 0.4814932346343994),\n",
              " ('tears', 0.4806995093822479),\n",
              " ('meant', 0.45831236243247986),\n",
              " ('hall', 0.4531801640987396),\n",
              " ('five', 0.4507332742214203)]"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"four\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPLDPgzBmQXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c698886-653f-4784-dca0-7cf23431bf51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('party', 0.5427762866020203),\n",
              " ('hatter', 0.5423594117164612),\n",
              " ('butter', 0.5289287567138672),\n",
              " ('dormouse', 0.4976823627948761),\n",
              " ('isnt', 0.4844900071620941)]"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"tea\"], topn=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este resultado muestra la capacidad del modelo para captar relaciones entre términos numéricos, pero también refleja asociaciones contextuales más amplias que pueden no ser evidentes al principio."
      ],
      "metadata": {
        "id": "xfWXi0JLdXSn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_UvHPMMklOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ceb3ba1-3b6c-4b4d-8e00-0904dc5e7cf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('few', 0.30428820848464966),\n",
              " ('have', 0.2928236126899719),\n",
              " ('off', 0.2698812484741211),\n",
              " ('all', 0.2266821414232254),\n",
              " ('my', 0.21503491699695587),\n",
              " ('then', 0.2082972377538681),\n",
              " ('than', 0.19965201616287231),\n",
              " ('but', 0.17975692451000214),\n",
              " ('your', 0.17862875759601593),\n",
              " ('not', 0.1772613376379013)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Ensayar con una palabra que no está en el vocabulario:\n",
        "w2v_model.wv.most_similar(negative=[\"alice\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al ensayar con palabras que no estaban en el vocavulario, se rompe e indica que no puede encontrar esa palabra en el espacio de embeddings."
      ],
      "metadata": {
        "id": "U71r3xeUfMDP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs36uiIfXqKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901f544f-338d-43ab-9537-1bb9508797b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.72359675 -0.65630376  0.8748923  -0.6998992  -0.10982101 -0.86644155\n",
            " -0.9201054   0.16177148  0.03043167 -0.09675397 -0.42376873 -0.71386427\n",
            " -0.93904054 -0.698123   -0.6914818  -0.49163905 -0.5594138  -1.1269171\n",
            " -0.34781718 -0.31737244 -0.4012126  -0.6961447   0.14150496 -0.84146345\n",
            " -0.554353   -0.6213085   0.629245    0.19253297  0.04656784 -1.5105101\n",
            "  0.71966875 -1.1712055   0.09669682 -0.65266746 -0.459713    0.29190573\n",
            " -0.15555511  0.15915354 -0.49867797 -1.06214    -0.12257899  1.706344\n",
            " -1.0654626  -0.7678665   0.2996435   0.22190249 -1.0669166  -0.3794111\n",
            " -0.11469608 -0.72338426]\n"
          ]
        }
      ],
      "source": [
        "# el método `get_vector` permite obtener los vectores:\n",
        "vector_love = w2v_model.wv.get_vector(\"sister\")\n",
        "print(vector_love)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqT1lpC0XqKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db94a18d-cf2c-4a6d-ba21-6c2b0f742d96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sister', 1.0),\n",
              " ('adventures', 0.644229531288147),\n",
              " ('dream', 0.5812686681747437),\n",
              " ('tired', 0.5325693488121033),\n",
              " ('trees', 0.5214706063270569),\n",
              " ('strange', 0.5104166865348816),\n",
              " ('late', 0.49911707639694214),\n",
              " ('writing', 0.48238879442214966),\n",
              " ('use', 0.48053568601608276),\n",
              " ('twice', 0.46622058749198914)]"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ],
      "source": [
        "# el método `most_similar` también permite comparar a partir de vectores\n",
        "w2v_model.wv.most_similar(vector_love)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7Yu56bAXqKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c711f8b-ffaa-45c1-e8c0-f4a919780215"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('knave', 0.606650710105896),\n",
              " ('king', 0.547720193862915),\n",
              " ('hurried', 0.5469918251037598),\n",
              " ('hearts', 0.5276579260826111),\n",
              " ('shrill', 0.5261293649673462),\n",
              " ('moved', 0.5155027508735657),\n",
              " ('court', 0.4903791844844818),\n",
              " ('jumped', 0.48588117957115173),\n",
              " ('reply', 0.48563677072525024),\n",
              " ('last', 0.47801950573921204)]"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"queen\"], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este resultado refleja el contexto narrativo en el que queen está inmersa, mostrando relaciones no solo con otros personajes de la realeza, sino también con términos que describen acciones y características asociadas a ella. Esto demuestra que el modelo captura tanto relaciones semánticas explícitas (personajes, lugares) como características contextuales más sutiles."
      ],
      "metadata": {
        "id": "pVSRrnyleHu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 - Test de Analogías"
      ],
      "metadata": {
        "id": "p4PihRVR661l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "para llevar a cabo el test de analogías, primero vamos a explorar las palabras mas frecuentes y partir de ellas para hacer las analogías."
      ],
      "metadata": {
        "id": "a-G5U1dCMqYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener más palabras frecuentes (por ejemplo, las 50 más frecuentes)\n",
        "most_frequent_words_extended = w2v_model.wv.index_to_key[:50]\n",
        "\n",
        "# Filtrar las stop words\n",
        "filtered_most_frequent_words_extended = [word for word in most_frequent_words_extended if word not in stop_words]\n",
        "\n",
        "print(filtered_most_frequent_words_extended)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0woBGXUTM3sB",
        "outputId": "2154c4dd-9fb8-49fc-e382-48e3076b592c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['said', 'alice', 'little', 'one', 'like', 'know', 'would']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Listar algunas palabras en el vocabulario\n",
        "vocabulary = list(w2v_model.wv.index_to_key)\n",
        "print(vocabulary[:100])  # Muestra las primeras 50 palabras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx81T589boS-",
        "outputId": "4a6d982c-4dbe-4033-96dc-8f70c1572283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'and', 'to', 'a', 'she', 'it', 'of', 'said', 'i', 'alice', 'in', 'you', 'was', 'that', 'as', 'her', 'at', 'on', 'with', 'all', 'had', 'but', 'for', 'so', 'be', 'very', 'not', 'what', 'this', 'little', 'they', 'he', 'out', 'its', 'is', 'down', 'one', 'up', 'his', 'if', 'about', 'then', 'no', 'were', 'like', 'know', 'them', 'would', 'again', 'herself', 'went', 'do', 'have', 'when', 'could', 'or', 'there', 'thought', 'off', 'time', 'me', 'queen', 'into', 'see', 'how', 'your', 'who', 'did', 'king', 'well', 'dont', 'my', 'now', 'began', 'im', 'by', 'an', 'turtle', 'mock', 'quite', 'gryphon', 'way', 'hatter', 'are', 'think', 'their', 'just', 'much', 'some', 'go', 'say', 'thing', 'only', 'which', 'first', 'more', 'head', 'rabbit', 'here', 'voice']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test de analogía - Caso #1\n",
        "\n",
        "analogy_result = w2v_model.wv.most_similar(positive=['alice', 'king'], negative=['queen'], topn=1)\n",
        "print(\"Resultado de la analogía:\", analogy_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UKmYaB0dw6h",
        "outputId": "8a316b14-e29c-4138-dd92-cbcf9206cd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado de la analogía: [('said', 0.5856814384460449)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La palabra \"said\" arroja un número de similitud coseno de 0.58; lo que marca una relación marcada y sugiere que el modelo ha aprendido que \"Alice\" y \"king\" en el texto se relacionan con la acción de hablar o a diálogos."
      ],
      "metadata": {
        "id": "kFtXToVOmPNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test de analogía - Caso #2\n",
        "\n",
        "analogy_result = w2v_model.wv.most_similar(positive=['queen', 'king'], negative=['rabbit'], topn=1)\n",
        "print(\"Resultado de la analogía:\", analogy_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1x46ls1dQyl",
        "outputId": "912d47d8-d3c4-4d12-9b8c-65b064c2df18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado de la analogía: [('everybody', 0.5471579432487488)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí también se marca una relación entre \"queen\" y \"king\" respecto a \"everybody\". Lo podemos interpretar como que los primeros evocan acciones referidos a todos los personajes/púbico. Tiene sentido por la dirigencia general que se relaciona con estos 2 conceptos."
      ],
      "metadata": {
        "id": "ACRTlLl-oh-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test de analogía - Caso #3\n",
        "\n",
        "analogy_result = w2v_model.wv.most_similar(positive=['she', 'king'], negative=['man'], topn=1)\n",
        "print(\"Resultado de la analogía:\", analogy_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ectW0ifT7AFL",
        "outputId": "736d83ef-0781-45e8-a92c-57b430f062ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado de la analogía: [('trees', 0.38349515199661255)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí la relación es baja, este resultado podría indicar que el modelo no ha aprendido adecuadamente las relaciones de género o las relaciones específicas de personajes dentro del contexto de \"Alice's Adventures in Wonderland\"."
      ],
      "metadata": {
        "id": "uk82VmvspXcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test de analogía - Caso #4\n",
        "\n",
        "analogy_result = w2v_model.wv.most_similar(positive=['king', 'say'], negative=['queen'], topn=1)\n",
        "print(\"Resultado de la analogía:\", analogy_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMzv0vrcdqX3",
        "outputId": "2160979f-c53e-4fa3-f81a-a5b7273c8eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado de la analogía: [('hastily', 0.5080660581588745)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g8UVWe6lFmh"
      },
      "source": [
        "### 6 - Visualizar agrupación de vectores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDxEVXAivjr9"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "def reduce_dimensions(model, num_dimensions = 2 ):\n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index_to_key)\n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    return vectors, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCCXtDpcugmd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "b7c269cf-24ef-4d8d-9856-84c0967b08ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d35c313e-38d9-48d9-8f38-565b40c6b4ed\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d35c313e-38d9-48d9-8f38-565b40c6b4ed\")) {                    Plotly.newPlot(                        \"d35c313e-38d9-48d9-8f38-565b40c6b4ed\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"the\",\"and\",\"to\",\"a\",\"she\",\"it\",\"of\",\"said\",\"i\",\"alice\",\"in\",\"you\",\"was\",\"that\",\"as\",\"her\",\"at\",\"on\",\"with\",\"all\",\"had\",\"but\",\"for\",\"so\",\"be\",\"very\",\"not\",\"what\",\"this\",\"little\",\"they\",\"he\",\"out\",\"its\",\"is\",\"down\",\"one\",\"up\",\"his\",\"if\",\"about\",\"then\",\"no\",\"were\",\"like\",\"know\",\"them\",\"would\",\"again\",\"herself\",\"went\",\"do\",\"have\",\"when\",\"could\",\"or\",\"there\",\"thought\",\"off\",\"time\",\"me\",\"queen\",\"into\",\"see\",\"how\",\"your\",\"who\",\"did\",\"king\",\"well\",\"dont\",\"my\",\"now\",\"began\",\"im\",\"by\",\"an\",\"turtle\",\"mock\",\"quite\",\"gryphon\",\"way\",\"hatter\",\"are\",\"think\",\"their\",\"just\",\"much\",\"some\",\"go\",\"say\",\"thing\",\"only\",\"which\",\"first\",\"more\",\"head\",\"rabbit\",\"here\",\"voice\",\"come\",\"never\",\"get\",\"got\",\"must\",\"looked\",\"after\",\"such\",\"him\",\"round\",\"two\",\"over\",\"came\",\"tone\",\"any\",\"great\",\"back\",\"dormouse\",\"duchess\",\"mouse\",\"before\",\"other\",\"been\",\"why\",\"oh\",\"from\",\"cat\",\"can\",\"ive\",\"nothing\",\"ill\",\"thats\",\"march\",\"large\",\"long\",\"tell\",\"right\",\"found\",\"last\",\"looking\",\"once\",\"put\",\"will\",\"hare\",\"next\",\"white\",\"made\",\"heard\",\"door\",\"replied\",\"look\",\"dear\",\"moment\",\"day\",\"things\",\"we\",\"three\",\"eyes\",\"cant\",\"might\",\"poor\",\"seemed\",\"going\",\"should\",\"good\",\"make\",\"too\",\"upon\",\"course\",\"shall\",\"soon\",\"away\",\"rather\",\"without\",\"wont\",\"sure\",\"same\",\"caterpillar\",\"theres\",\"than\",\"while\",\"half\",\"added\",\"youre\",\"felt\",\"took\",\"getting\",\"ever\",\"another\",\"jury\",\"yet\",\"take\",\"hand\",\"find\",\"words\",\"till\",\"wish\",\"minute\",\"cried\",\"however\"],\"x\":[-9.450321197509766,-1.2404505014419556,14.862687110900879,18.469491958618164,0.8084253072738647,6.640007495880127,-10.677570343017578,0.13187062740325928,18.468929290771484,-2.2651164531707764,-11.580510139465332,3.2491989135742188,1.0072671175003052,-6.335385322570801,-14.370479583740234,21.52318000793457,15.938135147094727,-12.018574714660645,-1.781972050666809,0.21490423381328583,3.137871265411377,-19.662771224975586,4.515997409820557,21.222869873046875,-9.745119094848633,-0.09192728996276855,1.5161895751953125,-3.6694202423095703,-7.603856086730957,-5.714869499206543,3.372596025466919,-8.02744197845459,-5.259170055389404,-2.6602723598480225,18.705219268798828,8.212096214294434,4.712996482849121,-10.34341812133789,-0.7390684485435486,0.11880236864089966,2.0937893390655518,-11.609367370605469,4.3084025382995605,19.84867286682129,-19.90391731262207,2.949120283126831,-3.5567216873168945,-10.184146881103516,-2.6871485710144043,-0.0797138661146164,1.002096176147461,3.0477633476257324,18.5919189453125,5.754063129425049,-8.766378402709961,-13.918939590454102,-6.973663806915283,13.566221237182617,17.26898193359375,14.325154304504395,-2.233612060546875,3.6423075199127197,5.428098201751709,5.413014888763428,-11.21175765991211,-19.483776092529297,-8.67224407196045,11.564314842224121,14.870172500610352,-3.189837694168091,-6.913787841796875,6.624392986297607,-8.871883392333984,4.249302864074707,-6.151516914367676,-0.9993327260017395,-5.683224201202393,-5.437495708465576,-16.442672729492188,14.320302963256836,4.665921211242676,3.4148366451263428,-8.891550064086914,-12.908953666687012,8.52703857421875,15.812570571899414,14.266814231872559,6.712594509124756,-11.670804023742676,-16.518678665161133,12.012432098388672,9.33182430267334,-7.380440711975098,-10.70777702331543,0.5197154879570007,8.933388710021973,-7.276590824127197,-8.041512489318848,8.961461067199707,-4.511605739593506,13.244278907775879,0.9182485342025757,-18.824565887451172,9.433274269104004,0.11695585399866104,-5.01121187210083,12.446000099182129,-13.188121795654297,-21.078046798706055,-17.590707778930664,4.958393096923828,7.940733909606934,-4.34769344329834,-1.3337050676345825,5.692500591278076,9.658447265625,6.804423809051514,5.995446681976318,-6.796677112579346,19.323923110961914,-14.653386116027832,-8.188835144042969,-6.165148735046387,5.1118950843811035,12.174392700195312,12.976964950561523,-15.783210754394531,-16.18765640258789,9.614542961120605,-13.721237182617188,-2.76936674118042,-7.436224460601807,-2.423543930053711,4.904807090759277,-9.585000038146973,4.397771835327148,6.120957851409912,-1.3981019258499146,-7.396901607513428,-7.506222724914551,-2.757345676422119,18.24048614501953,7.074624061584473,-5.392712116241455,5.882562160491943,19.060274124145508,19.191293716430664,0.007363059092313051,5.974102020263672,-19.059297561645508,3.99709415435791,8.111042976379395,8.535967826843262,5.838123798370361,0.6176797747612,5.967936992645264,5.221480369567871,7.632559299468994,-15.519944190979004,18.020885467529297,9.207687377929688,22.124284744262695,12.29745864868164,-17.55988883972168,1.8971260786056519,1.898324966430664,9.496917724609375,-6.306324005126953,0.8348729014396667,-12.47781753540039,-19.04524803161621,-3.4497945308685303,0.815549373626709,-10.37633228302002,16.713640213012695,5.333336353302002,-15.000165939331055,-5.776318073272705,0.20033542811870575,-1.9454851150512695,16.67498207092285,13.713515281677246,8.322157859802246,7.902440071105957,-2.9116246700286865,7.00581693649292,-2.5948781967163086,-15.5349760055542,-2.4203391075134277,-7.782953262329102,-13.775720596313477,-4.718060493469238,9.347990036010742,14.71878433227539,-8.091165542602539,-7.35606050491333,-12.70196533203125,7.6194844245910645,3.103867769241333,-11.757509231567383],\"xaxis\":\"x\",\"y\":[-0.23632320761680603,17.66393280029297,-12.362215995788574,-18.989538192749023,1.2883853912353516,-11.122666358947754,-5.4252495765686035,-11.051002502441406,-18.98874282836914,-8.767781257629395,-0.9911385774612427,-13.865270614624023,19.2330379486084,-8.861930847167969,-6.377589702606201,3.0193021297454834,-14.230659484863281,-19.693456649780273,-14.80125617980957,-11.117532730102539,-4.705491065979004,3.42061448097229,10.996293067932129,-0.9125559329986572,19.13599967956543,-6.782944679260254,-13.14804458618164,17.80657196044922,5.172126770019531,-15.07347297668457,-1.784093976020813,7.512282848358154,-12.305733680725098,3.8655800819396973,6.8780598640441895,4.10346794128418,-4.898129463195801,-5.376439571380615,12.78908920288086,4.794116497039795,18.282075881958008,3.9528262615203857,0.8537704348564148,11.056109428405762,8.94282054901123,16.802223205566406,-3.5577242374420166,-10.654489517211914,-18.22735023498535,8.039349555969238,-22.7594051361084,-14.615345001220703,-14.080238342285156,-8.662275314331055,12.420855522155762,-11.852069854736328,6.713862895965576,-9.297192573547363,13.423443794250488,-5.179659366607666,-23.19682502746582,-6.182385444641113,-0.6019260287284851,-2.1011011600494385,-12.880401611328125,9.328136444091797,-17.79473304748535,-4.884015083312988,-12.311978340148926,-12.329111099243164,16.792770385742188,-0.09608621150255203,0.4816736876964569,-0.7664116024971008,4.829944610595703,10.820408821105957,14.60610580444336,-1.3555079698562622,-8.77530574798584,4.134592533111572,14.563117027282715,6.388678073883057,1.1355587244033813,-17.1214599609375,7.641339302062988,-8.127845764160156,9.046817779541016,-7.310323715209961,-8.432007789611816,-14.358030319213867,-5.038014888763428,-6.554890155792236,-8.827141761779785,1.1190741062164307,-7.124679088592529,8.918745994567871,-2.381096363067627,11.67028522491455,-13.661988258361816,3.0780978202819824,-2.095371723175049,13.543461799621582,13.661482810974121,-0.3035825192928314,15.88825511932373,11.349339485168457,-2.5748579502105713,-3.701984405517578,5.791516304016113,4.82038688659668,9.497227668762207,9.360295295715332,5.403064250946045,1.1465102434158325,19.508949279785156,3.5720083713531494,-9.506589889526367,5.212188243865967,11.283400535583496,-4.04573392868042,4.7134575843811035,-1.4250978231430054,14.083362579345703,-13.805196762084961,-2.497303009033203,2.5996646881103516,-1.5986229181289673,-8.489755630493164,-6.839454650878906,-4.867472171783447,-0.8909226059913635,-5.1422438621521,8.596349716186523,-2.088007926940918,3.189950704574585,-8.717376708984375,-5.3650078773498535,-20.290651321411133,1.0146567821502686,2.781873941421509,2.5216894149780273,-6.401035308837891,-4.393585681915283,-15.312141418457031,8.251049041748047,-12.94483757019043,-7.899937629699707,-0.8634021878242493,1.0997469425201416,-6.5128092765808105,-20.690763473510742,-12.496642112731934,-18.238508224487305,-1.3459174633026123,-16.697420120239258,3.5477166175842285,-15.366333961486816,1.0274560451507568,8.815008163452148,8.679254531860352,9.003835678100586,5.672379970550537,-12.221134185791016,6.674112796783447,9.223000526428223,-3.3426177501678467,4.815539836883545,8.161200523376465,12.91244888305664,11.92339038848877,-1.5555782318115234,6.438063144683838,-18.636510848999023,10.863187789916992,3.270721435546875,-9.421894073486328,3.4862875938415527,-10.934968948364258,14.945813179016113,-10.387676239013672,17.019479751586914,-0.5379931330680847,1.2405750751495361,-6.229044437408447,-16.24570655822754,-14.414390563964844,-2.0646562576293945,5.289272308349609,6.544091701507568,1.1055049896240234,-13.281146049499512,-6.061075687408447,-3.2751121520996094,4.136600017547607,-5.791698455810547,-10.513751983642578,-7.129031181335449,5.919800758361816,16.008153915405273,4.1093316078186035],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d35c313e-38d9-48d9-8f38-565b40c6b4ed');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "vecs, labels = reduce_dimensions(w2v_model)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQrtKmzNXqKx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2afa968e-6bce-4d68-b3d6-5812321a6016"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"80cb4a10-a383-43d8-93c1-4e1f49c90294\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"80cb4a10-a383-43d8-93c1-4e1f49c90294\")) {                    Plotly.newPlot(                        \"80cb4a10-a383-43d8-93c1-4e1f49c90294\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"size\":2},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"the\",\"and\",\"to\",\"a\",\"she\",\"it\",\"of\",\"said\",\"i\",\"alice\",\"in\",\"you\",\"was\",\"that\",\"as\",\"her\",\"at\",\"on\",\"with\",\"all\",\"had\",\"but\",\"for\",\"so\",\"be\",\"very\",\"not\",\"what\",\"this\",\"little\",\"they\",\"he\",\"out\",\"its\",\"is\",\"down\",\"one\",\"up\",\"his\",\"if\",\"about\",\"then\",\"no\",\"were\",\"like\",\"know\",\"them\",\"would\",\"again\",\"herself\",\"went\",\"do\",\"have\",\"when\",\"could\",\"or\",\"there\",\"thought\",\"off\",\"time\",\"me\",\"queen\",\"into\",\"see\",\"how\",\"your\",\"who\",\"did\",\"king\",\"well\",\"dont\",\"my\",\"now\",\"began\",\"im\",\"by\",\"an\",\"turtle\",\"mock\",\"quite\",\"gryphon\",\"way\",\"hatter\",\"are\",\"think\",\"their\",\"just\",\"much\",\"some\",\"go\",\"say\",\"thing\",\"only\",\"which\",\"first\",\"more\",\"head\",\"rabbit\",\"here\",\"voice\",\"come\",\"never\",\"get\",\"got\",\"must\",\"looked\",\"after\",\"such\",\"him\",\"round\",\"two\",\"over\",\"came\",\"tone\",\"any\",\"great\",\"back\",\"dormouse\",\"duchess\",\"mouse\",\"before\",\"other\",\"been\",\"why\",\"oh\",\"from\",\"cat\",\"can\",\"ive\",\"nothing\",\"ill\",\"thats\",\"march\",\"large\",\"long\",\"tell\",\"right\",\"found\",\"last\",\"looking\",\"once\",\"put\",\"will\",\"hare\",\"next\",\"white\",\"made\",\"heard\",\"door\",\"replied\",\"look\",\"dear\",\"moment\",\"day\",\"things\",\"we\",\"three\",\"eyes\",\"cant\",\"might\",\"poor\",\"seemed\",\"going\",\"should\",\"good\",\"make\",\"too\",\"upon\",\"course\",\"shall\",\"soon\",\"away\",\"rather\",\"without\",\"wont\",\"sure\",\"same\",\"caterpillar\",\"theres\",\"than\",\"while\",\"half\",\"added\",\"youre\",\"felt\",\"took\",\"getting\",\"ever\",\"another\",\"jury\",\"yet\",\"take\",\"hand\",\"find\",\"words\",\"till\",\"wish\",\"minute\",\"cried\",\"however\"],\"x\":[-28.32896614074707,44.13539505004883,37.79549026489258,-15.260929107666016,32.33152770996094,28.34741973876953,5.276805400848389,-23.437389373779297,-15.16695785522461,-24.64453887939453,-33.922306060791016,6.143918991088867,36.5872688293457,-34.208187103271484,-8.094590187072754,42.05863571166992,-30.972328186035156,-17.714855194091797,-29.57412338256836,-20.12884521484375,16.631099700927734,-5.766824722290039,5.789047718048096,32.764163970947266,2.513319253921509,-5.591897964477539,36.73338317871094,38.698333740234375,4.665356159210205,-13.695974349975586,21.997657775878906,-3.2106709480285645,-14.461767196655273,-0.24446578323841095,19.4160213470459,22.17538833618164,-31.63620948791504,8.466553688049316,22.853757858276367,19.479454040527344,30.131467819213867,16.574310302734375,11.412893295288086,4.054349899291992,-37.36040496826172,19.784439086914062,7.388437747955322,-5.444243907928467,-28.6267032623291,18.24738311767578,-17.844934463500977,3.976024866104126,7.068851470947266,-19.718101501464844,47.81325149536133,5.487971305847168,-6.1655592918396,-30.13023567199707,-20.82638931274414,-42.86313247680664,50.00406265258789,-17.80947494506836,-3.2308716773986816,8.339323997497559,-6.123340129852295,-40.88700485229492,-44.68006896972656,-15.889823913574219,39.63908386230469,-28.022520065307617,0.3127194344997406,17.63627052307129,-23.021015167236328,26.836843490600586,-3.2912867069244385,4.56024694442749,-16.412282943725586,-6.954914093017578,-35.496646881103516,25.706600189208984,10.091854095458984,10.265989303588867,-20.208629608154297,24.36397933959961,36.4564208984375,-33.140811920166016,-2.3299970626831055,-43.53255844116211,-39.052059173583984,-0.7918968796730042,-21.596240997314453,25.11111831665039,-41.546119689941406,-10.968010902404785,-0.2406795173883438,0.8349178433418274,-20.547969818115234,44.480133056640625,-26.359210968017578,10.705326080322266,-7.614573955535889,-23.68097686767578,5.277385711669922,19.093849182128906,44.854225158691406,-13.724495887756348,-6.793069839477539,-14.118081092834473,9.518434524536133,-30.510528564453125,-4.46012020111084,35.30057907104492,-47.807456970214844,-3.023615598678589,17.94617462158203,26.91780662536621,-22.498554229736328,26.63736343383789,13.093953132629395,-30.55752944946289,-16.11522674560547,-28.986804962158203,-19.80712127685547,-37.12551498413086,-10.188802719116211,15.944856643676758,-19.15800666809082,-32.61820602416992,29.664608001708984,1.4198296070098877,-11.768312454223633,-1.8636231422424316,-3.3452253341674805,11.922700881958008,15.529169082641602,14.413078308105469,-26.840747833251953,6.223538398742676,13.064652442932129,4.957289218902588,-18.56015968322754,27.39662742614746,4.750945091247559,-13.669135093688965,28.343603134155273,-13.152139663696289,-32.17573547363281,-11.152247428894043,21.485828399658203,-17.870311737060547,-10.786581993103027,-23.08218002319336,12.053752899169922,2.8652641773223877,9.017491340637207,36.143280029296875,5.981705188751221,11.81404972076416,19.4011287689209,-1.1434283256530762,-3.5856494903564453,-3.0151820182800293,-27.863862991333008,-26.24095344543457,13.923646926879883,-9.786152839660645,23.576841354370117,-16.397977828979492,7.072039604187012,30.350141525268555,-51.866966247558594,0.6276251077651978,17.315401077270508,-21.20381736755371,13.930953979492188,-10.117658615112305,-20.435810089111328,-6.310464382171631,-0.4114941656589508,-29.13103675842285,-18.448049545288086,21.586374282836914,15.31190013885498,25.007957458496094,-18.63398551940918,14.2026948928833,36.642921447753906,44.26774215698242,-3.813445568084717,8.689409255981445,-1.1473196744918823,-16.41103744506836,-2.973503351211548,23.559314727783203,-7.794878959655762,-36.59860610961914,-27.573984146118164,16.38881492614746,14.967080116271973,13.81406021118164],\"y\":[-14.377608299255371,17.202735900878906,15.092832565307617,-35.47947692871094,6.9361653327941895,34.90605926513672,8.078511238098145,-3.1590263843536377,-31.495153427124023,-3.0413589477539062,-4.645227909088135,8.74290943145752,-7.265368938446045,19.554826736450195,26.40734100341797,-24.95166778564453,27.189573287963867,33.7545051574707,26.689695358276367,-1.9246045351028442,1.0457731485366821,-33.88167953491211,-35.127349853515625,-36.62917709350586,15.40911865234375,17.51468276977539,12.372624397277832,26.542116165161133,-22.97203826904297,12.616334915161133,6.957019805908203,-38.62379837036133,-14.717535018920898,-3.1107583045959473,37.49998474121094,-16.79143714904785,5.875301837921143,3.851807117462158,4.843437194824219,-13.978440284729004,-16.51064682006836,3.2338695526123047,23.68366813659668,-25.00705909729004,-22.18503761291504,-43.332130432128906,-15.740992546081543,32.70118713378906,-28.01079750061035,19.535425186157227,38.42485046386719,10.853083610534668,-13.494363784790039,7.630340099334717,1.2169201374053955,-11.228667259216309,-27.248367309570312,-26.875503540039062,-29.703140258789062,25.6724796295166,-9.006196022033691,23.448596954345703,23.0767822265625,18.690731048583984,1.1308783292770386,-20.746334075927734,12.915424346923828,23.012086868286133,19.69099998474121,-7.774381160736084,-2.75693941116333,-10.763855934143066,-17.87342643737793,18.890745162963867,-17.124265670776367,-48.26435470581055,-0.9008769989013672,8.991883277893066,26.05355453491211,19.244705200195312,-30.04849624633789,17.05961036682129,-24.213735580444336,0.7494855523109436,10.317279815673828,15.45141315460205,34.960792541503906,-12.972437858581543,6.140712738037109,12.649495124816895,24.01667594909668,-5.907559871673584,13.11125373840332,-7.082668304443359,11.27229118347168,12.762810707092285,-10.187080383300781,7.723496437072754,-23.476903915405273,-20.986576080322266,2.2518677711486816,18.97703742980957,30.25069808959961,-35.15864181518555,2.0671730041503906,16.71612548828125,-1.1219488382339478,17.59686279296875,27.10891342163086,-18.774106979370117,-30.246278762817383,-5.8709516525268555,-0.8419025540351868,-18.045751571655273,44.35226058959961,-11.197269439697266,23.929384231567383,-15.64209270477295,17.529212951660156,-26.42207908630371,-0.015551796182990074,-2.8004276752471924,3.4749948978424072,-11.456223487854004,-5.09850549697876,27.194686889648438,-1.246445894241333,21.366769790649414,-5.575201034545898,4.144384860992432,-2.550626516342163,-21.132953643798828,-6.7143235206604,14.32992935180664,9.181528091430664,1.3581647872924805,-5.3379693031311035,13.419812202453613,-3.6446993350982666,-7.829361915588379,-16.708337783813477,14.623690605163574,-4.237940788269043,8.016469955444336,-5.927734375,46.307090759277344,-11.794514656066895,-12.176825523376465,-5.7139458656311035,-37.105167388916016,26.043325424194336,-18.65658950805664,3.4607458114624023,20.45253562927246,-43.61686706542969,-16.393373489379883,-15.22509765625,-11.701455116271973,9.598982810974121,27.119539260864258,12.194141387939453,-30.381591796875,20.04188346862793,-42.49944305419922,-30.2899227142334,35.373416900634766,-9.054677963256836,12.45391845703125,-3.327089309692383,-39.92866134643555,-0.3675828278064728,-31.589672088623047,-37.99359893798828,-12.3949613571167,31.8468017578125,5.3493475914001465,2.5973634719848633,-9.859399795532227,-41.677581787109375,-2.6717026233673096,-38.899261474609375,28.65790557861328,-16.679790496826172,2.3559539318084717,-24.58815574645996,-24.452428817749023,6.192425727844238,13.263439178466797,-34.94412612915039,-2.187891721725464,-6.880739212036133,-16.915679931640625,-19.747304916381836,24.686994552612305,-19.168519973754883,9.895076751708984,6.63346529006958,-13.507984161376953,-41.10218811035156,-0.00561295123770833],\"z\":[-7.298684597015381,2.0160489082336426,-16.936355590820312,-25.746103286743164,1.7353768348693848,14.847517013549805,21.637550354003906,36.928035736083984,-27.15024185180664,13.45195198059082,-11.50904655456543,-8.602770805358887,27.06955337524414,18.979928970336914,-4.1842360496521,5.256149768829346,9.0117769241333,11.824366569519043,29.53179931640625,40.68489456176758,-2.931934118270874,-13.761628150939941,9.507526397705078,-0.1956763118505478,-27.426599502563477,4.6655497550964355,8.939518928527832,6.401269435882568,27.5993595123291,43.94049835205078,1.4783779382705688,30.880321502685547,31.84081268310547,-36.34486389160156,-11.424744606018066,22.22451400756836,-36.8773193359375,21.52615737915039,15.530656814575195,-27.838857650756836,26.407604217529297,-44.50310516357422,21.738990783691406,-45.19584655761719,-15.428762435913086,6.161617279052734,-9.028141021728516,18.43170738220215,27.78948402404785,-12.709185600280762,2.5039963722229004,-3.9328806400299072,37.21931457519531,-38.189353942871094,-13.471632957458496,-49.34120178222656,29.20707130432129,-2.2615556716918945,5.4485039710998535,13.759523391723633,-1.556313395500183,42.181129455566406,-1.9816510677337646,-0.7974010109901428,-14.05915641784668,-11.411388397216797,-7.387343883514404,16.273174285888672,-15.88468074798584,30.105043411254883,40.21440505981445,42.2609748840332,-7.075253963470459,3.7932097911834717,28.308372497558594,17.205163955688477,-7.2803802490234375,2.785785436630249,-21.839080810546875,26.082992553710938,-1.449824571609497,31.836030960083008,-4.101914405822754,-43.899505615234375,-5.54884147644043,6.300920009613037,-4.9421515464782715,11.371475219726562,3.4290518760681152,-37.96294021606445,15.070199966430664,-16.408390045166016,16.548107147216797,-28.056093215942383,9.14571475982666,-20.366559982299805,5.227187156677246,-12.539556503295898,-21.996252059936523,9.846083641052246,-4.650997638702393,23.679092407226562,39.66702651977539,18.57785415649414,0.2068876475095749,-18.618087768554688,0.6298284530639648,30.53616714477539,-31.175519943237305,-34.52274703979492,7.726317882537842,-27.038869857788086,6.167547702789307,8.064992904663086,11.139492988586426,16.533802032470703,-31.723630905151367,-5.039748668670654,16.05865478515625,11.040419578552246,-20.733530044555664,2.3200905323028564,-6.250269889831543,-18.915374755859375,1.8683080673217773,9.96522331237793,-48.521507263183594,-24.507722854614258,-18.490825653076172,-52.16261672973633,10.896957397460938,-22.01898765563965,-21.44624137878418,-0.6320102214813232,20.565914154052734,-19.157817840576172,-39.17694091796875,11.006662368774414,17.395769119262695,16.505207061767578,8.095168113708496,14.58564281463623,25.765090942382812,41.300750732421875,-6.796209335327148,9.335434913635254,34.63405227661133,-6.865525245666504,35.767333984375,22.690019607543945,-30.092451095581055,-16.731714248657227,47.882259368896484,-1.4922674894332886,-19.066530227661133,4.8332037925720215,1.8602889776229858,33.31597137451172,32.75647735595703,5.591722011566162,-20.962053298950195,-18.464618682861328,-13.983448028564453,-5.721945762634277,8.451273918151855,-16.697782516479492,26.90382194519043,8.053629875183105,-22.866771697998047,-14.120110511779785,-6.626678466796875,-6.760982513427734,-21.533910751342773,18.054611206054688,29.69302749633789,-41.7085075378418,-23.489179611206055,29.771467208862305,-8.0349702835083,20.142257690429688,4.629632472991943,6.57316255569458,33.06304168701172,-17.258514404296875,27.95650291442871,-24.494678497314453,12.0077543258667,20.013671875,-5.94244384765625,14.580292701721191,-47.94084930419922,-31.154033660888672,-3.380159854888916,26.326475143432617,-14.660761833190918,26.267841339111328,3.8323843479156494,14.48300552368164,2.6042678356170654,-46.5549201965332],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('80cb4a10-a383-43d8-93c1-4e1f49c90294');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Graficar los embedddings en 3D\n",
        "\n",
        "vecs, labels = reduce_dimensions(w2v_model,3)\n",
        "\n",
        "fig = px.scatter_3d(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], z=vecs[:MAX_WORDS,2],text=labels[:MAX_WORDS])\n",
        "fig.update_traces(marker_size = 2)\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5THHCihXqKy"
      },
      "outputs": [],
      "source": [
        "# También se pueden guardar los vectores y labels como tsv para graficar en\n",
        "# http://projector.tensorflow.org/\n",
        "\n",
        "\n",
        "vectors = np.asarray(w2v_model.wv.vectors)\n",
        "labels = list(w2v_model.wv.index_to_key)\n",
        "\n",
        "np.savetxt(\"vectors.tsv\", vectors, delimiter=\"\\t\")\n",
        "\n",
        "with open(\"labels.tsv\", \"w\") as fp:\n",
        "    for item in labels:\n",
        "        fp.write(\"%s\\n\" % item)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7 - Conclusiones"
      ],
      "metadata": {
        "id": "eZU8mkog9LA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "• El modelo demostró esr efectivo en la captura de relaciones semánticas entre palabras, como vimos en los resultados de las pruebas de analogía. La similitud coseno en los resultados sugiere que el modelo ha aprendido relaciones relevantes en el contexto de \"Alice's Adventures in Wonderland\".\n",
        "\n",
        "\n",
        "**Resultados**:\n",
        "\n",
        "En el primer test de analogía, la asociación de \"said\" con \"alice\" y \"king\" sugiere que el modelo ha internalizado interacciones significativas entre personajes. Esta relación refleja diálogos y acciones q ocurren entre ellos.\n",
        "La prueba de analogía que involucra \"queen\" y \"king\" indica que el modelo ha capturado la relación de poder y autoridad entre estos personajes.\n",
        "El resultado menos satisfactorio en la prueba que involucra \"she\", \"king\", y \"man\" podría sugerir que el modelo no ha aprendido adecuadamente las relaciones de género o que el corpus tiene limitaciones en representar estas dinámicas.\n",
        "\n",
        "\n",
        "**Aspectos de Mejora:**\n",
        "\n",
        "Se entiende que a pesar de los resultados positivos, se podrían mejorar los resultados con un corpues mas grande y diverso de esta forma mejoraría las relacion entre conceptos menos comunes.\n"
      ],
      "metadata": {
        "id": "7k-os0iS9Tpy"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}